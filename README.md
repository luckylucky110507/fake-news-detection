# ğŸš¨ Fake News Detection System

A complete machine learning project that detects whether news articles are **FAKE** or **REAL** using Natural Language Processing and Logistic Regression.

**Current Model Performance:**
- âœ… **Accuracy: 96.81%**
- âœ… **Precision: 96.82%**
- âœ… **Recall: 96.81%**
- âœ… **F1-Score: 96.81%**

---

## ğŸ“‹ Project Structure

```
fake-news-detection/
â”œâ”€â”€ app.py                      # Streamlit web interface
â”œâ”€â”€ fake_real_news.csv         # Dataset (44,898 articles)
â”œâ”€â”€ fake_news_model.pkl        # Trained Logistic Regression model
â”œâ”€â”€ tfidf_vectorizer.pkl       # TF-IDF text vectorizer
â”œâ”€â”€ label_encoder.pkl          # Binary label encoder
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ .streamlit/
    â””â”€â”€ config.toml            # Streamlit configuration
```

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Run the Web App (Streamlit)

```bash
streamlit run app.py
```

Then open your browser to: `http://localhost:8501`

**Features:**
- âœ… Clean, user-friendly interface
- âœ… Real-time predictions
- âœ… Confidence scores
- âœ… Color-coded results (Green=Real, Red=Fake)
- âœ… Interactive sidebar information

### 3. Using the Model in Python

```python
import pickle
import numpy as np

# Load models
model = pickle.load(open("fake_news_model.pkl", "rb"))
vectorizer = pickle.load(open("tfidf_vectorizer.pkl", "rb"))
encoder = pickle.load(open("label_encoder.pkl", "rb"))

# Test news
news = "Your news article text here..."
cleaned = news.lower()
vector = vectorizer.transform([cleaned])
prediction = model.predict(vector)[0]
confidence = np.max(model.predict_proba(vector)[0]) * 100
label = encoder.inverse_transform([prediction])[0]

print(f"Prediction: {label} ({confidence:.2f}%)")
```

---

## ğŸ“Š Dataset

**Source:** `fake_real_news.csv`

**Statistics:**
- Total articles: **44,898**
- Fake news: **23,481** (52.3%)
- Real news: **21,417** (47.7%)
- Columns: `text`, `label`

---

## ğŸ¤– Model Details

### Algorithm
**Logistic Regression** - Fast, interpretable, and highly accurate

### Features
- **TF-IDF Vectorization**
  - Stop words removed
  - Unigrams (single words)
  - 2,000 features selected
  - Min frequency: 1, Max frequency: 95%

### Training Process
1. Load and clean data
2. Sample 10,000 articles for efficiency
3. Vectorize text using TF-IDF
4. Split into train (80%) / test (20%)
5. Train Logistic Regression model
6. Evaluate using multiple metrics

### Text Cleaning
```python
1. Convert to lowercase
2. Remove special characters (keep letters & spaces)
3. Remove extra whitespace
4. Strip leading/trailing spaces
```

---

## ğŸ“ˆ Performance Metrics

| Metric | Value |
|--------|-------|
| Accuracy | 96.81% |
| Precision | 96.82% |
| Recall | 96.81% |
| F1-Score | 96.81% |

**Interpretation:**
- Model correctly classifies ~97 out of 100 articles
- Balanced performance for both fake and real news
- Highly reliable predictions

---

## ğŸ“š File Descriptions

| File | Description |
|------|-------------|
| `app.py` | Main Streamlit web interface for predictions |
| `fake_real_news.csv` | Dataset with 44,898 labeled articles |
| `fake_news_model.pkl` | Pre-trained Logistic Regression model |
| `tfidf_vectorizer.pkl` | Fitted TF-IDF vectorizer (2000 features) |
| `label_encoder.pkl` | Binary label encoder (FAKE=0, REAL=1) |
| `requirements.txt` | Python package dependencies |
| `README.md` | Project documentation |
| `.gitignore` | Git configuration for version control |
| `.streamlit/config.toml` | Streamlit app configuration |

---

## ğŸ”§ Troubleshooting

### Models not loading
```
Error: Model file not found
Solution: Ensure all .pkl files are in the project folder
```

### Streamlit not starting
```bash
# Check if streamlit is installed
pip list | grep streamlit

# Reinstall if needed
pip install streamlit --upgrade
```

### Port 8501 already in use
```bash
# Run on different port
streamlit run app.py --server.port 8502
```

---

## ğŸ“¦ Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| pandas | >=2.0.0 | Data manipulation |
| numpy | >=1.24.0 | Numerical computing |
| scikit-learn | >=1.3.0 | ML algorithms |
| nltk | >=3.8 | NLP tools |
| streamlit | >=1.28.0 | Web interface |
| altair | >=4.2.0 | Visualization |

---

## ğŸ’¡ How It Works

### Prediction Pipeline

```
User Input Text
    â†“
Text Cleaning (lowercase, remove special chars)
    â†“
TF-IDF Vectorization (convert to numbers)
    â†“
Logistic Regression Model
    â†“
Probability Scores
    â†“
Classification: FAKE or REAL
    â†“
Display Results with Confidence
```

---

## âš ï¸ Limitations & Disclaimer

1. **Model Accuracy**: ~97% but not 100%
2. **Dataset Bias**: Trained on specific dataset
3. **Language**: Works best with English text
4. **Context**: Cannot verify sources or facts
5. **Use Responsibly**: 
   - Don't rely solely on this model
   - Cross-reference multiple sources
   - Combine with human judgment

---

## ğŸ“ Learning Insights

### Key Concepts Demonstrated
- âœ… Text preprocessing and NLP
- âœ… Feature extraction (TF-IDF)
- âœ… Machine learning model training
- âœ… Model evaluation and metrics
- âœ… Web app development (Streamlit)
- âœ… Pickle serialization
- âœ… CLI and GUI interfaces

---

## ğŸ“š File Descriptions

| File | Description |
|------|-------------|
| `app.py` | Main Streamlit web interface for predictions |
| `fake_real_news.csv` | Dataset with 44,898 labeled articles |
| `fake_news_model.pkl` | Pre-trained Logistic Regression model |
| `tfidf_vectorizer.pkl` | Fitted TF-IDF vectorizer (2000 features) |
| `label_encoder.pkl` | Binary label encoder (FAKE=0, REAL=1) |
| `requirements.txt` | Python package dependencies |
| `README.md` | Project documentation |
| `.gitignore` | Git configuration for version control |
| `.streamlit/config.toml` | Streamlit app configuration |

---

## ğŸ” Security Notes

- Models are safe pickle files
- No external API calls
- All processing local
- Dataset is public

---

## ğŸ“ Support

**To retrain the model:**
```bash
python train_fast.py    # Quick (~2 min)
python train_model.py   # Full training (~10+ min)
```

**To test model performance:**
```bash
python test_model.py
```

**To use the web app:**
```bash
streamlit run app.py
```

---

## ğŸ“„ License

This project is for educational purposes. Feel free to modify and use as needed.

---

## âœ¨ Features

- âœ… High accuracy (96.81%)
- âœ… Fast predictions (<1 second)
- âœ… Beautiful web interface
- âœ… CLI support
- âœ… Detailed metrics
- âœ… Easy to extend
- âœ… Well documented

---

**Last Updated:** February 2, 2026  
**Model Version:** 1.0  
**Status:** âœ… Production Ready
